# -*- coding: utf-8 -*-
"""Investment Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZX5dFMYbGkMJgEnzDJVzKwpcasNYS6p8

# 21FS Investments Selected Quantitative Tools - Course Project
"""

"""### import"""
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn import preprocessing
from matplotlib.lines import Line2D

"""### WindowGenerator"""


class WindowGenerator:
    def __init__(self, input_width, label_width, shift, input_columns=None, label_columns=None):

        # Work out the label column indices.
        self.label_columns = label_columns
        if label_columns is not None:
            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}
        self.train_label_indices = {name: i for i, name in enumerate(train_df.columns)}

        # ...and the input column indices
        self.input_columns = input_columns
        if input_columns is not None:
            self.input_columns_indices = {name: i for i, name in enumerate(input_columns)}
        self.train_input_indices = {name: i for i, name in enumerate(train_df.columns)}

        # Work out the window parameters.
        self.input_width = input_width
        self.label_width = label_width
        self.shift = shift

        self.total_window_size = input_width + shift

        self.input_slice = slice(0, input_width)
        self.input_indices = np.arange(self.total_window_size)[self.input_slice]

        self.label_start = self.total_window_size - self.label_width
        self.labels_slice = slice(self.label_start, None)
        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]

    def split_window(self, features):
        inputs = features[:, self.input_slice, :]
        labels = features[:, self.labels_slice, :]
        if self.input_columns is not None:
            inputs = tf.stack([inputs[:, :, self.train_input_indices[name]] for name in self.input_columns], axis=-1)
        if self.label_columns is not None:
            labels = tf.stack([labels[:, :, self.train_label_indices[name]] for name in self.label_columns], axis=-1)
        return inputs, labels

    def make_dataset(self, data, shuffle=False, batchsize=500, ):
        data = np.array(data, dtype=np.float32)
        ds = tf.keras.preprocessing.timeseries_dataset_from_array(data=data, targets=None,
                                                                  sequence_length=self.total_window_size,
                                                                  sequence_stride=1, sampling_rate=1, shuffle=shuffle,
                                                                  batch_size=batchsize)
        ds = ds.map(self.split_window)
        return ds


"""### Prepare data"""
lf = 1  # look forward
ks = 5  # kernel size
lw = 1  # label width
lb = 30  # look back

# PREPARE DATA
df = pd.read_excel('data_sp500_2.xls')
df = df.set_index(df.Date)
df0 = df.drop(columns='Date')
df0 = df0.pct_change()
df0 = df0.dropna(axis=0, how='all')
df0 = df0.dropna()

df1 = df0
input_labels = df0.columns.to_list()
for inlbl in input_labels:
    df1[inlbl] = df0.loc[:, inlbl].rolling(5).mean()

df1 = df1.asfreq('W', method='ffill')
df1 = df1.dropna()

# df1['SPXs'] = df1.loc[:, ['SPX.US']].pct_change().rolling(5).mean()
# input_labels.append('SPXs')
# df1['SPX'] = df0.loc[:, ['SPX.US']].pct_change()
# df1 = df1.dropna()

"""### Take sign of the return"""
df1['SPX_sign'] = df1['SPX.US'].apply(func=lambda x: 1 if x > 0 else 0)

"""### Make dataset"""
# Splitting
n = len(df1)
frac_trai, frac_vali = 0.6, 0.2

train_df = df1[0:int(n * frac_trai)]
valid_df = df1[int(n * frac_trai):int(n * (frac_trai + frac_vali))]
test_df = df1[int(n * (frac_trai + frac_vali)):]

# Normalizing data
mm_scaler = preprocessing.StandardScaler()
train_df_m = mm_scaler.fit_transform(train_df)
valid_df_m = mm_scaler.transform(valid_df)
test_df_m = mm_scaler.transform(test_df)
train_df = pd.DataFrame(train_df_m, index=train_df.index, columns=train_df.columns)
train_df['SPX_sign'] = train_df['SPX_sign'].apply(func=lambda x: 1 if x > 0 else 0)
valid_df = pd.DataFrame(valid_df_m, index=valid_df.index, columns=valid_df.columns)
valid_df['SPX_sign'] = valid_df['SPX_sign'].apply(func=lambda x: 1 if x > 0 else 0)
test_df = pd.DataFrame(test_df_m, index=test_df.index, columns=test_df.columns)
test_df['SPX_sign'] = test_df['SPX_sign'].apply(func=lambda x: 1 if x > 0 else 0)

# Make datasets
window = WindowGenerator(input_width=lb, label_width=lw, shift=lf, input_columns=input_labels, label_columns=['SPX.US'])
train_data = window.make_dataset(train_df)
valid_data = window.make_dataset(valid_df)
test_data = window.make_dataset(test_df)

# Make datasets for classification
window_binary = WindowGenerator(input_width=lb, label_width=lw, shift=lf, input_columns=input_labels,
                                label_columns=['SPX_sign'])
train_data_binary = window_binary.make_dataset(train_df)
valid_data_binary = window_binary.make_dataset(valid_df)
test_data_binary = window_binary.make_dataset(test_df)

dropout_rate = np.arange(0, 1, 0.1)
perf_vs_dropout = {}
sharpe_vs_dropout = {}

fig_acc, fig_wea = None, None

"""RNN Binary classification"""
for d in range(len(dropout_rate)):
    # use the sign
    model_rnn_binary = tf.keras.Sequential()
    model_rnn_binary.add(tf.keras.layers.Dropout(dropout_rate[d]))
    model_rnn_binary.add(
        tf.keras.layers.SimpleRNN(units=5, return_sequences=False, return_state=False, activation=None, use_bias=True))
    model_rnn_binary.add(tf.keras.layers.Dense(1, activation='sigmoid', use_bias=True))

    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, mode='min')
    model_rnn_binary.compile(loss=tf.losses.BinaryCrossentropy(), optimizer=tf.optimizers.Adam(learning_rate=0.01),
                             metrics=tf.metrics.BinaryAccuracy())
    model_rnn_binary.run_eagerly = False

    """#### train"""
    history_rnn_binary = model_rnn_binary.fit(train_data_binary, epochs=100, validation_data=valid_data_binary,
                                              callbacks=[early_stopping])

    perf_vs_dropout[d] = history_rnn_binary.history['val_binary_accuracy'][-1]

    y_pred_rnn_binary = model_rnn_binary.predict(test_data_binary)
    y_true_binary = np.concatenate([y for x, y in test_data_binary], axis=0)

    """#### plot"""

    blue_shade = (0.9 - dropout_rate[d], 0.9 - dropout_rate[d], 1)
    red_shade = (min(1.6 - dropout_rate[d], 1), 0.9 - dropout_rate[d], 0.9 - dropout_rate[d])

    if fig_acc is None:
        fig_acc = plt.figure()
        ax_acc = fig_acc.add_subplot(1, 1, 1)
    else:
        ax_acc = fig_acc.axes[0]

    ax_acc.plot(history_rnn_binary.history['binary_accuracy'], color=blue_shade)
    ax_acc.plot(history_rnn_binary.history['val_binary_accuracy'], color=red_shade)

    if fig_wea is None:
        fig_wea = plt.figure()
        ax_wea = fig_wea.add_subplot(1, 1, 1)
    else:
        ax_wea = fig_wea.axes[0]

    y_mkt = df1['SPX.US'].iloc[int(n * (frac_trai + frac_vali)) + lb + lf - 1:, ]
    # position taking: simple switch
    pos_binary = np.sign(np.squeeze(y_pred_rnn_binary[:, -1]) - 0.5)
    pnl_binary = pos_binary * y_mkt
    if d == 0:
        ax_wea.plot(y_mkt.index, np.cumprod(1 + y_mkt), 'b--', label='SP500TR')
    ax_wea.plot(y_mkt.index, np.cumprod(1 + pnl_binary), color=red_shade,
                label='Binary RNN (DO = ' + "{:.1f}".format(dropout_rate[d]) + ')')

    sharpe_vs_dropout[d] = np.sqrt(252 / 5) * np.mean(pnl_binary) / np.std(pnl_binary)

    print('Done with dropout rate = ' + "{:.1f}".format(dropout_rate[d]))

ax_acc.set_title('Model accuracy')
ax_acc.set_ylabel('Accuracy')
ax_acc.set_xlabel('Epoch')
custom_lines = [Line2D([0], [0], color='b', lw=2),
                Line2D([0], [0], color='r', lw=2)]
fig_acc.legend(custom_lines, ['Train', 'Validation'], bbox_to_anchor=(0.35, 0.35, 0, 0.5))

ax_wea.set_ylabel('Cumulative wealth')
ax_wea.set_xlabel('Date')
fig_wea.autofmt_xdate()
fig_wea.legend(bbox_to_anchor=(0.425, 0.35, 0, 0.5), prop={'size': 8})

# Validation Binary Accuracy vs. Dropout rate
perf_vs_dropout_dict = perf_vs_dropout.items()
perf_vs_dropout_list = list(perf_vs_dropout_dict)
perf_vs_dropout_arr = np.array(perf_vs_dropout_list)
fig_perf = plt.figure(7)
ax_perf = fig_perf.add_subplot(1, 1, 1)
ax_perf.plot(dropout_rate, perf_vs_dropout_arr[:, 1], 'Dr-')
ax_perf.set_ylabel('Validation Binary Accuracy')
ax_perf.set_xlabel('Dropout rate')
ax_perf.set_xticks(dropout_rate)
